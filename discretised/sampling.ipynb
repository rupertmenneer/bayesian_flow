{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('./rds/hpc-work/MLMI4/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "checkpoint_file = '/home/rfsm2/rds/hpc-work/MLMI4/bfn_model_checkpoint.pth'\n",
    "from discretised.trainer import DiscretisedBFNTrainer\n",
    "# 150e3a3656bc3e6c76366ee98da5b0fd9f7c16ea\n",
    "trainer = DiscretisedBFNTrainer(wandb_project_name=None, checkpoint_file=checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "1) generate samples, look at generation over time\n",
    "2) generate samples twice the size - see what happens\n",
    "3) generate input/output distributions\n",
    "4) view mean plot over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.utils import plot_tensor_images\n",
    "bfn_model = trainer.bfn_model\n",
    "# bfn_model.sample_generation_for_discretised_data(self, sample_shape:tuple = (8, 32, 32, 3), n_steps:int = 100):\n",
    "samples, priors = bfn_model.sample_generation_for_discretised_data(sample_shape = (8, 32, 32, 3), n_steps = 20, seed=7)\n",
    "plot_tensor_images(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input/output dists over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_tracker_idx = 3\n",
    "idx = 2\n",
    "t = torch.tensor(range(1, 1001, 100))\n",
    "sample_over_time = priors[idx, :, prior_tracker_idx, t].reshape((32, 32, 3, -1)).permute((-1, 0, 1, 2))\n",
    "print(sample_over_time.shape, samples.shape, len(sample_over_time))\n",
    "plot_tensor_images(sample_over_time, n=len(sample_over_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different sampling steps (same seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.utils import plot_tensor_images\n",
    "\n",
    "# n_steps = [10, 25, 100, 1000, 4000]\n",
    "n_steps = [10, 25, 50, 100, 1000, 4000]\n",
    "sample_for_n = []\n",
    "for n in n_steps:\n",
    "    samples, priors = bfn_model.sample_generation_for_discretised_data(sample_shape = (8, 32, 32, 3), n_steps = n, seed=7)\n",
    "    sample_for_n.append(samples)\n",
    "\n",
    "for s in sample_for_n:\n",
    "    plot_tensor_images(s)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
