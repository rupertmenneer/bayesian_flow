{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/Users/rupertmenneer/Documents/git/bayesian_flow/')\n",
    "from datasets.bfn_discretised_toy_data import DiscretisedBimodalData\n",
    "from discretised.bfn_discretised import BayesianFlowNetworkDiscretised\n",
    "from models.simple_models import SimpleNeuralNetworkDiscretised\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_printoptions(precision=5, sci_mode=False)\n",
    "k = 5\n",
    "dataset = DiscretisedBimodalData(n=5000, k=k)\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "device = 'cpu'\n",
    "bfn_model = BayesianFlowNetworkDiscretised(SimpleNeuralNetworkDiscretised(), device=device, k=k).to(device)\n",
    "optim = AdamW(bfn_model.parameters(), lr=3e-4, betas=(0.9, 0.98), weight_decay=0.01)\n",
    "\n",
    "ema = ExponentialMovingAverage(bfn_model.parameters(), decay=0.995)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "epochs = 1000\n",
    "losses = []\n",
    "n_batches_track = 100\n",
    "for i in range(epochs):\n",
    "    # print(i)\n",
    "    epoch_losses = []\n",
    "    for _, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "        loss = bfn_model.discrete_time_loss_for_discretised_data(batch.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(bfn_model.parameters(), max_norm=2.0)\n",
    "        optim.step()\n",
    "        # Update the moving average with the new parameters from the last optimizer step\n",
    "        ema.update()\n",
    "        epoch_losses.append(loss.item())\n",
    "    if i%n_batches_track == 0:\n",
    "        print(f'Epoch {i+1}/{epochs}, Loss: {torch.mean(torch.tensor(epoch_losses))}')\n",
    "    losses.append(torch.mean(torch.tensor(epoch_losses)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.shape)\n",
    "plt.hist(batch.squeeze(), bins=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(1, 25, (32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "bs=1000\n",
    "dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "batch = next(iter(dataloader))\n",
    "print(len(torch.unique(batch)))\n",
    "samples, priors = bfn_model.sample_generation_for_discretised_data(sample_shape=(bs, 1), n_steps=100)\n",
    "samples = samples.to(torch.float32)\n",
    "print(len(torch.unique(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "bs=256\n",
    "dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "batch = next(iter(dataloader))\n",
    "batch.shape\n",
    "with ema.average_parameters():\n",
    "    samples, priors = bfn_model.sample_generation_for_discretised_data(sample_shape=(bs, 1), n_steps=100)\n",
    "    samples = samples.to(torch.float32)\n",
    "\n",
    "plt.hist(samples.detach().numpy(), alpha=0.8, bins=k, label='BFN Samples', color='orange')\n",
    "plt.hist(batch.numpy(), bins=k, alpha=0.5, label='True Samples')\n",
    "plt.title('Samples from Discretised BFN model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(priors.detach().numpy()[:, :, 0, :].squeeze().T, label='Prior mu', alpha=0.03);\n",
    "plt.xlabel('Generation step')\n",
    "plt.ylabel('Prior mu')\n",
    "plt.title('Mean samples over time from Discretised BFN model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
