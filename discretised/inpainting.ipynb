{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('./rds/hpc-work/MLMI4/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "checkpoint_file = '/home/rfsm2/rds/hpc-work/MLMI4/bfn_model_checkpoint.pth'\n",
    "from discretised.trainer import DiscretisedBFNTrainer\n",
    "# 150e3a3656bc3e6c76366ee98da5b0fd9f7c16ea\n",
    "trainer = DiscretisedBFNTrainer(wandb_project_name=None, checkpoint_file=checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.utils import plot_tensor_images\n",
    "# take a val batch and create a box mask in the middle\n",
    "val_batch = next(iter(trainer.val_dls))\n",
    "val_mask = torch.ones_like(val_batch)\n",
    "val_mask[:, 9:23, 9:23, :] = 0.\n",
    "plot_tensor_images(val_batch*(val_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.utils import plot_tensor_images\n",
    "bs = 8\n",
    "steps=100\n",
    "repaint_steps=20\n",
    "samples_repaint, priors_repaint = trainer.bfn_model.repaint_sample_generation_for_discretised_data(val_batch[:bs], val_mask[:bs], sample_shape = (bs, 32, 32, 3), n_steps = steps, seed=1, repaint_steps=repaint_steps)\n",
    "# samples, priors = trainer.bfn_model.sample_generation_for_discretised_data(sample_shape = (bs, 32, 32, 3), n_steps = steps, seed=1)\n",
    "# plot_tensor_images(val_batch-(val_mask*0.8))\n",
    "plot_tensor_images(samples_repaint)\n",
    "# plot_tensor_images(samples)\n",
    "plot_tensor_images(val_batch*(val_mask))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
