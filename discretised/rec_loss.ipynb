{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/rupertmenneer/Documents/git/bayesian_flow/')\n",
    "import torch\n",
    "from datasets.utils import plot_tensor_images\n",
    "from discretised.trainer import DiscretisedBFNTrainer\n",
    "# 150e3a3656bc3e6c76366ee98da5b0fd9f7c16ea\n",
    "trainer = DiscretisedBFNTrainer(wandb_project_name=None)\n",
    "bfn_model = trainer.bfn_model\n",
    "test_dls = trainer.test_dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from bfn_discretised import safe_log\n",
    "from datasets.utils import float_to_idx, idx_to_float, quantize\n",
    "\n",
    "class DiscretizedCtsDistribution():\n",
    "    def __init__(self, cts_dist, num_bins, device, batch_dims, clip=True, min_prob=1e-5):\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_width = 2.0 / num_bins\n",
    "        self.half_bin_width = self.bin_width / 2.0\n",
    "        self.cts_dist = cts_dist\n",
    "        self.log_bin_width = math.log(self.bin_width)\n",
    "        self.batch_dims = batch_dims\n",
    "        self.clip = clip\n",
    "        self.min_prob = min_prob\n",
    "\n",
    "    def prob(self, x):\n",
    "            class_idx = float_to_idx(x, self.num_bins)\n",
    "            centre = idx_to_float(class_idx, self.num_bins)\n",
    "            cdf_lo = self.cts_dist.cdf(centre - self.half_bin_width)\n",
    "            cdf_hi = self.cts_dist.cdf(centre + self.half_bin_width)\n",
    "            if self.clip:\n",
    "                cdf_lo = torch.where(class_idx <= 0, torch.zeros_like(centre), cdf_lo)\n",
    "                cdf_hi = torch.where(class_idx >= (self.num_bins - 1), torch.ones_like(centre), cdf_hi)\n",
    "                return cdf_hi - cdf_lo\n",
    "            else:\n",
    "                cdf_min = self.cts_dist.cdf(torch.zeros_like(centre) - 1)\n",
    "                cdf_max = self.cts_dist.cdf(torch.ones_like(centre))\n",
    "                cdf_range = cdf_max - cdf_min\n",
    "                cdf_mask = cdf_range < self.min_prob\n",
    "                cdf_range = torch.where(cdf_mask, (cdf_range * 0) + 1, cdf_range)\n",
    "                prob = (cdf_hi - cdf_lo) / cdf_range\n",
    "                return torch.where(cdf_mask, (prob * 0) + (1 / self.num_bins), prob)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        prob = self.prob(x)\n",
    "        return torch.where(\n",
    "            prob < self.min_prob,\n",
    "            self.cts_dist.log_prob(quantize(x, self.num_bins)) + self.log_bin_width,\n",
    "            safe_log(prob),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from discretised.bfn_discretised import right_pad_dims_to\n",
    "\n",
    "def reconstruction_loss(data, mean):\n",
    "    flat_data = data.flatten(start_dim=1)\n",
    "    t = torch.ones_like(data).flatten(start_dim=1).float()\n",
    "    noise_dev =  bfn_model.sigma_one\n",
    "    num_bins = bfn_model.k\n",
    "    final_dist = torch.distributions.Normal(mean, noise_dev)\n",
    "    final_dist = DiscretizedCtsDistribution(final_dist, num_bins, device=t.device, batch_dims=mean.ndim - 1)\n",
    "    reconstruction_loss = -final_dist.log_prob(flat_data)\n",
    "    return reconstruction_loss\n",
    "\n",
    "recon_losses = []\n",
    "for test_batch in test_dls:\n",
    "    bs = test_batch.shape[0]\n",
    "    test_batch = test_batch.view(bs, -1)\n",
    "    t = right_pad_dims_to(bfn_model.get_time_at_t(1., bs=bs), test_batch)\n",
    "    gamma = right_pad_dims_to(bfn_model.get_gamma_t(t), test_batch)\n",
    "    # Shape-> Tensor[B, D] from the discretised data, create noisy sender sample from a normal centered around data and known variance\n",
    "    std = torch.sqrt(gamma*(1-gamma))\n",
    "    mean = test_batch*gamma\n",
    "    sender_mu_sample = bfn_model.get_normal_sample(mean, std)\n",
    "    output_distribution = bfn_model.discretised_output_distribution(sender_mu_sample, t, gamma=gamma)\n",
    "    mean = torch.sum(output_distribution*bfn_model.k_centers, dim=-1)\n",
    "    rec_loss = reconstruction_loss(test_batch, mean).flatten(start_dim=1).mean()\n",
    "    recon_losses.append(torch.tensor(rec_loss).mean())\n",
    "\n",
    "recon_losses = torch.stack(recon_losses)\n",
    "print(recon_losses.mean())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
